# 第二单元 音频应用入门
欢迎来到Hugging Face音频课程的第二单元！在此之前，我们探索了音频数据的基础知识，并学习了如何使用Hugging Face `Datasets` 和 Hugging Face `Transformers` 库处理音频数据集。我们讨论了采样率、振幅、比特深度、波形和时频谱等各种概念，并了解了如何预处理数据以准备预训练模型。

至此，您可能已经迫不及待地想了解Hugging Face `Transformers` 可以处理的音频任务，而且您已经掌握了深入学习所需的所有基础知识！让我们来看看一些令人惊叹的音频任务示例：

+ 音频分类：轻松将音频片段分为不同类别。您可以识别一段录音是狗叫还是猫叫，或者一首歌曲属于哪种音乐类型。
+ 自动语音识别：通过自动转录将音频片段转换为文本。你可以获得某人说话录音的文本表征，比如 "你今天过得怎么样？这对记笔记非常有用！
+ 说话人日志： 有没有想过谁在录音中说话？有了Hugging Face `Transformers`，你就能在音频片段的任何给定时间内识别出说话的人是谁。想象一下，在 "Alice "和 "Bob "的对话录音中，你能分辨出是谁在说话。
+ 文本到语音：创建文本的旁白版本，可用于制作有声读物、帮助实现无障碍环境，或为游戏中的 NPC 配音。有了Hugging Face `Transformers`，你就可以轻松做到这一点！

在本单元中，您将学习如何使用Hugging Face `Transformers` 中的 `pipeline()` 函数使用预训练模型来完成这些任务。具体来说，我们将了解如何将预训练模型用于音频分类、自动语音识别和音频生成。让我们开始吧！