# 实践练习
在本单元中，我们探讨了微调 ASR 模型所面临的挑战，认识到在新语言上微调像 Whisper 这样的模型（即使是一个小的检查点）所需的时间和资源。为了提供实践经验，我们设计了一个练习，让您在使用较小的数据集的同时，了解微调 ASR 模型的过程。本练习的主要目的是让您熟悉这一过程，而不是期望获得生产级别的结果。我们有意设定了一个较低的指标，以确保即使资源有限，您也应该能够实现这一目标。

说明如下：

+ 使用 `"PolyAI/minds14"` 数据集的美式英语（"en-US"）子集微调 `"openai/whisper-tiny"` 模型。
+ 将**前 450 个示例用于训练**，其余用于评估。使用 `.map` 方法预处理数据集时，请确保设置 `num_proc=1`（这将确保模型正确提交评估）。
+ 要评估模型，请使用本单元所述的 `wer` 和 `wer_ortho` 指标。但是，不要将指标乘以 100 转换成百分比（例如，如果 WER 是 42%，我们希望在本练习中看到的值是 0.42）。

微调模型后，请确保将其上传到 🤗 Hub，并使用以下 kwargs：

```python
kwargs = {
     "dataset_tags": "PolyAI/minds14",
    "finetuned_from": "openai/whisper-tiny",
    "tasks": "automatic-speech-recognition",
}
```

如果您的模型的标准化 WER (wer) 低于 **0.37**，您将通过这项作业。
