# **æ–‡æœ¬åˆ°è¯­éŸ³çš„é¢„è®­ç»ƒæ¨¡å‹** 

ä¸ ASRï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«ï¼‰å’ŒéŸ³é¢‘åˆ†ç±»ä»»åŠ¡ç›¸æ¯”ï¼Œå¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹æ£€æŸ¥ç‚¹è¦å°‘å¾—å¤šã€‚åœ¨ ğŸ¤— Hub ä¸Šï¼Œæ‚¨å¯ä»¥æ‰¾åˆ°è¿‘ 300 ä¸ªåˆé€‚çš„æ£€æŸ¥ç‚¹ã€‚åœ¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹å…³æ³¨ ğŸ¤— `Transformers` åº“ä¸­çš„ä¸¤ç§æ¶æ„--SpeechT5 å’Œ Massive Multilingual Speech (MMS)ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ¢è®¨å¦‚ä½•åœ¨ `Transformers` åº“ä¸­ä½¿ç”¨è¿™äº›é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œ TTSã€‚

## **SpeechT5** 

[SpeechT5](https://arxiv.org/abs/2110.07205)æ˜¯å¾®è½¯å…¬å¸çš„æ•–å›é€¸ç­‰äººå‘å¸ƒçš„æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†ä¸€ç³»åˆ—è¯­éŸ³ä»»åŠ¡ã€‚åœ¨æœ¬å•å…ƒä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹æ”¾åœ¨æ–‡æœ¬åˆ°è¯­éŸ³æ–¹é¢ï¼Œä½†è¯¥æ¨¡å‹æ—¢å¯ç”¨äºè¯­éŸ³åˆ°æ–‡æœ¬ä»»åŠ¡ï¼ˆè‡ªåŠ¨è¯­éŸ³è¯†åˆ«æˆ–è¯´è¯äººè¯†åˆ«ï¼‰ï¼Œä¹Ÿå¯ç”¨äºè¯­éŸ³åˆ°è¯­éŸ³ä»»åŠ¡ï¼ˆå¦‚è¯­éŸ³å¢å¼ºæˆ–ä¸åŒè¯­éŸ³ä¹‹é—´çš„è½¬æ¢ï¼‰ã€‚è¿™è¦å½’åŠŸäºæ¨¡å‹çš„è®¾è®¡å’Œé¢„è®­ç»ƒæ–¹å¼ã€‚

SpeechT5 çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªæ™®é€šçš„Transformerç¼–ç å™¨-è§£ç å™¨æ¨¡å‹ã€‚å°±åƒå…¶ä»–Transformerä¸€æ ·ï¼Œç¼–ç å™¨-è§£ç å™¨ç½‘ç»œä½¿ç”¨éšè—è¡¨ç¤ºæ³•å¯¹åºåˆ—-åºåˆ—å˜æ¢è¿›è¡Œå»ºæ¨¡ã€‚SpeechT5 æ”¯æŒçš„æ‰€æœ‰ä»»åŠ¡éƒ½é‡‡ç”¨ç›¸åŒçš„Transformeréª¨å¹²ã€‚

è¯¥Transformerè¿˜è¾…ä»¥å…­ä¸ªç‰¹å®šæ¨¡æ€ï¼ˆè¯­éŸ³/æ–‡æœ¬ï¼‰*å‰ç½®ç½‘ç»œ*å’Œ*åç½®ç½‘ç»œ*ã€‚è¾“å…¥çš„è¯­éŸ³æˆ–æ–‡æœ¬ï¼ˆå–å†³äºä»»åŠ¡ï¼‰é€šè¿‡ç›¸åº”çš„å‰ç½®ç½‘ç»œè¿›è¡Œé¢„å¤„ç†ï¼Œä»¥è·å¾— Transformer å¯ä»¥ä½¿ç”¨çš„éšè—è¡¨å¾ã€‚ç„¶åï¼ŒTransformerçš„è¾“å‡ºè¢«ä¼ é€’ç»™åç½®ç½‘ç»œï¼Œåè€…å°†åˆ©ç”¨Transformerçš„è¾“å‡ºç”Ÿæˆç›®æ ‡æ¨¡æ€çš„è¾“å‡ºã€‚

è¿™å°±æ˜¯è¯¥æ¶æ„çš„å¤–è§‚ï¼ˆå›¾ç‰‡æ¥è‡ªåŸå§‹è®ºæ–‡ï¼‰ï¼š

![architecture](images/architecture.jpg)

SpeechT5 é¦–å…ˆä½¿ç”¨å¤§è§„æ¨¡æ— æ ‡è®°è¯­éŸ³å’Œæ–‡æœ¬æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œä»¥è·å¾—ä¸åŒæ¨¡æ€çš„ç»Ÿä¸€è¡¨ç¤ºã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæ‰€æœ‰å‰ç½®ç½‘ç»œå’Œåç½®ç½‘ç»œåŒæ—¶ä½¿ç”¨ã€‚

é¢„è®­ç»ƒå®Œæˆåï¼Œæ•´ä¸ªç¼–ç å™¨-è§£ç å™¨éª¨å¹²ç½‘ç»œå°†é’ˆå¯¹æ¯ä¸ªä»»åŠ¡è¿›è¡Œå¾®è°ƒã€‚åœ¨è¿™ä¸€æ­¥ä¸­ï¼Œåªä½¿ç”¨ä¸ç‰¹å®šä»»åŠ¡ç›¸å…³çš„å‰ç½®ç½‘ç»œå’Œåç½®ç½‘ç»œã€‚ä¾‹å¦‚ï¼Œè¦ä½¿ç”¨ SpeechT5 è¿›è¡Œæ–‡æœ¬åˆ°è¯­éŸ³çš„è½¬æ¢ï¼Œå°±éœ€è¦æ–‡æœ¬ç¼–ç å™¨å‰ç½®ç½‘ç»œæ¥å¤„ç†æ–‡æœ¬è¾“å…¥ï¼Œè¯­éŸ³è§£ç å™¨å‰ç½®ç½‘ç»œå’Œåç½®ç½‘ç»œæ¥å¤„ç†è¯­éŸ³è¾“å‡ºã€‚

è¿™ç§æ–¹æ³•å¯ä»¥è·å¾—å¤šä¸ªé’ˆå¯¹ä¸åŒè¯­éŸ³ä»»åŠ¡è¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ï¼Œè¿™äº›æ¨¡å‹éƒ½å—ç›Šäºåœ¨æ— æ ‡è®°æ•°æ®ä¸Šè¿›è¡Œçš„åˆå§‹é¢„è®­ç»ƒã€‚

> å°½ç®¡å¾®è°ƒåçš„æ¨¡å‹ä¸€å¼€å§‹ä½¿ç”¨çš„æ˜¯æ¥è‡ªå…±äº«é¢„è®­ç»ƒæ¨¡å‹çš„åŒä¸€ç»„æƒé‡ï¼Œä½†æœ€ç»ˆçš„ç‰ˆæœ¬å´å¤§ç›¸å¾„åº­ã€‚ä¾‹å¦‚ï¼Œæ‚¨æ— æ³•ä½¿ç”¨å¾®è°ƒåçš„ ASR æ¨¡å‹ï¼Œç„¶åå°†å‰ç½®ç½‘ç»œå’Œåç½®ç½‘ç»œäº’æ¢ï¼Œä»¥è·å¾—ä¸€ä¸ªæœ‰æ•ˆçš„ TTS æ¨¡å‹ã€‚SpeechT5 æ˜¯çµæ´»çš„ï¼Œä½†ä¸æ˜¯é‚£ä¹ˆçµæ´»ï¼›)

è®©æˆ‘ä»¬æ¥çœ‹çœ‹ SpeechT5 å…·ä½“ç”¨äº TTS ä»»åŠ¡çš„å‰ç½®ç½‘å’Œåç½®ç½‘æœ‰å“ªäº›ï¼š

- æ–‡æœ¬ç¼–ç å™¨å‰ç½®ç½‘ç»œï¼š æ–‡æœ¬åµŒå…¥å°†æ–‡æœ¬tokenæ˜ å°„åˆ°ç¼–ç å™¨æ‰€æœŸæœ›çš„éšè—è¡¨ç¤ºã€‚è¿™ä¸ BERT ç­‰ NLP æ¨¡å‹ä¸­çš„æƒ…å†µç±»ä¼¼ã€‚
- è¯­éŸ³è§£ç å™¨å‰ç½®ç½‘ç»œï¼š å®ƒå°†å¯¹æ•°æ¢…å°”é¢‘è°±å›¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶ä½¿ç”¨ä¸€ç³»åˆ—çº¿æ€§å±‚å°†é¢‘è°±å›¾å‹ç¼©ä¸ºéšè—è¡¨å¾ã€‚
- è¯­éŸ³è§£ç å™¨åç½®ç½‘ç»œï¼š åç½®ç½‘ç»œé¢„æµ‹è¾“å‡ºé¢‘è°±å›¾çš„æ®‹å·®ï¼Œå¹¶ç”¨äºå®Œå–„ç»“æœã€‚

ç»“åˆèµ·æ¥ï¼Œè¿™å°±æ˜¯ç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³çš„ SpeechT5 æ¶æ„ï¼š

![tts](images/tts.jpg)

å¦‚æ‚¨æ‰€è§ï¼Œè¾“å‡ºæ˜¯ä¸€ä¸ªå¯¹æ•°æ¢…å°”å›¾ï¼Œè€Œä¸æ˜¯æœ€ç»ˆæ³¢å½¢ã€‚å¦‚æœæ‚¨è¿˜è®°å¾—ï¼Œæˆ‘ä»¬åœ¨[ç¬¬ä¸‰å•å…ƒ](chapter3/refresher_on_transformer_models.md)ä¸­ç®€è¦è®¨è®ºè¿‡è¿™ä¸ªè¯é¢˜ã€‚ç”ŸæˆéŸ³é¢‘çš„æ¨¡å‹é€šå¸¸ä¼šäº§ç”Ÿä¸€ä¸ªå¯¹æ•°æ¢…å°”é¢‘è°±å›¾ï¼Œéœ€è¦é€šè¿‡ä¸€ä¸ªé¢å¤–çš„ç¥ç»ç½‘ç»œï¼ˆç§°ä¸ºå£°ç å™¨ï¼‰å°†å…¶è½¬æ¢ä¸ºæ³¢å½¢ã€‚

è®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•åšåˆ°è¿™ä¸€ç‚¹ã€‚

é¦–å…ˆï¼Œè®©æˆ‘ä»¬ä» ğŸ¤— Hub ä¸­åŠ è½½ç»è¿‡å¾®è°ƒçš„ TTS SpeechT5 æ¨¡å‹ï¼Œä»¥åŠç”¨äºæ ‡è®°åŒ–å’Œç‰¹å¾æå–çš„å¤„ç†å™¨å¯¹è±¡ï¼š

```python
from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech

processor = SpeechT5Processor.from_pretrained("microsoft/speecht5_tts") 
model = SpeechT5ForTextToSpeech.from_pretrained("microsoft/speecht5_tts")
```

æ¥ä¸‹æ¥ï¼Œå¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ã€‚

```python
inputs = processor(text="Don't count the days, make the days count.", return_tensors="pt")
```

SpeechT5 TTS æ¨¡å‹å¹¶ä¸å±€é™äºä¸ºå•ä¸ªè¯´è¯è€…åˆ›å»ºè¯­éŸ³ã€‚ç›¸åï¼Œå®ƒä½¿ç”¨æ‰€è°“çš„æ‰¬å£°å™¨åµŒå…¥æ¥æ•æ‰ç‰¹å®šæ‰¬å£°å™¨çš„è¯­éŸ³ç‰¹å¾ã€‚

> è¯´è¯è€…åµŒå…¥æ˜¯ä¸€ç§ä»¥ç´§å‡‘çš„æ–¹å¼è¡¨ç¤ºè¯´è¯è€…èº«ä»½çš„æ–¹æ³•ï¼Œå®ƒæ˜¯ä¸€ä¸ªå›ºå®šå¤§å°çš„å‘é‡ï¼Œä¸è¯­å¥çš„é•¿åº¦æ— å…³ã€‚è¿™äº›åµŒå…¥å¯ä»¥æ•æ‰åˆ°è¯´è¯è€…çš„å£°éŸ³ã€å£éŸ³ã€è¯­è°ƒä»¥åŠå…¶ä»–åŒºåˆ«äºå…¶ä»–è¯´è¯è€…çš„ç‹¬ç‰¹ç‰¹å¾çš„åŸºæœ¬ä¿¡æ¯ã€‚è¿™ç§åµŒå…¥å¯ç”¨äºæ‰¬å£°å™¨éªŒè¯ã€æ‰¬å£°å™¨æ—¥è®°åŒ–ã€æ‰¬å£°å™¨è¯†åˆ«ç­‰ã€‚ç”Ÿæˆè¯´è¯è€…åµŒå…¥çš„æœ€å¸¸è§æŠ€æœ¯åŒ…æ‹¬
>
> - I-å‘é‡ï¼ˆèº«ä»½å‘é‡ï¼‰ï¼š I-Vectors åŸºäºé«˜æ–¯æ··åˆæ¨¡å‹ (GMM)ã€‚å®ƒä»¬å°†æ‰¬å£°å™¨è¡¨ç¤ºä¸ºä½ç»´å®šé•¿å‘é‡ï¼Œè¿™äº›å‘é‡æ¥è‡ªæ‰¬å£°å™¨ç‰¹å®š GMM çš„ç»Ÿè®¡é‡ï¼Œå¹¶ä»¥æ— ç›‘ç£æ–¹å¼è·å¾—ã€‚
> - X å‘é‡ï¼š X å‘é‡ä½¿ç”¨æ·±åº¦ç¥ç»ç½‘ç»œ (DNN) å¾—å‡ºï¼Œé€šè¿‡ç»“åˆæ—¶é—´ä¸Šä¸‹æ–‡æ¥æ•æ‰å¸§çº§è¯´è¯è€…ä¿¡æ¯ã€‚
>
> ä¸ I-Vectors ç›¸æ¯”ï¼Œ[X-Vectors](https://www.danielpovey.com/files/2018_icassp_xvectors.pdf)æ˜¯ä¸€ç§æœ€å…ˆè¿›çš„æ–¹æ³•ï¼Œåœ¨è¯„ä¼°æ•°æ®é›†ä¸Šæ˜¾ç¤ºå‡ºæ›´ä¼˜è¶Šçš„æ€§èƒ½ã€‚æ·±åº¦ç¥ç»ç½‘ç»œç”¨äºè·å– X å‘é‡ï¼šå®ƒé€šè¿‡è®­ç»ƒæ¥åŒºåˆ†ä¸åŒçš„è¯´è¯äººï¼Œå¹¶å°†å¯å˜é•¿åº¦çš„è¯­éŸ³æ˜ å°„åˆ°å›ºå®šç»´åº¦çš„åµŒå…¥ã€‚æ‚¨ä¹Ÿå¯ä»¥åŠ è½½æå‰è®¡ç®—å¥½çš„ X å‘é‡è¯´è¯è€…åµŒå…¥ï¼Œå®ƒå°†å›Šæ‹¬ç‰¹å®šè¯´è¯è€…çš„è¯´è¯ç‰¹å¾ã€‚

è®©æˆ‘ä»¬ä» Hub ä¸Šçš„ä¸€ä¸ªæ•°æ®é›†ä¸­åŠ è½½è¿™æ ·ä¸€ä¸ªè¯´è¯è€…åµŒå…¥ã€‚æˆ‘ä»¬ä½¿ç”¨[æ­¤è„šæœ¬](https://huggingface.co/mechanicalsea/speecht5-vc/blob/main/manifest/utils/prep_cmu_arctic_spkemb.py)ä»[CMU ARCTIC æ•°æ®é›†ä¸­](http://www.festvox.org/cmu_arctic/)è·å–äº†åµŒå…¥ï¼Œä½†ä»»ä½• X-Vector åµŒå…¥éƒ½å¯ä»¥ä½¿ç”¨ã€‚

```python
from datasets import load_dataset 
embeddings_dataset = load_dataset("Matthijs/cmu-arctic-xvectors", split="validation") import torch 
speaker_embeddings = torch.tensor(embeddings_dataset[7306]["xvector"]).unsqueeze(0)
```

æ‰¬å£°å™¨åµŒå…¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º (1, 512) çš„å¼ é‡ã€‚è¿™ä¸ªç‰¹å®šçš„æ‰¬å£°å™¨åµŒå…¥æè¿°äº†ä¸€ä¸ªå¥³å£°ã€‚

æ­¤æ—¶ï¼Œæˆ‘ä»¬å·²ç»æœ‰è¶³å¤Ÿçš„è¾“å…¥æ¥ç”Ÿæˆå¯¹æ•°æ¢…å°”é¢‘è°±å›¾ä½œä¸ºè¾“å‡ºï¼Œä½ å¯ä»¥è¿™æ ·åšï¼š

```python
spectrogram = model.generate_speech(inputs["input_ids"], speaker_embeddings)
```

è¿™å°†è¾“å‡ºä¸€ä¸ªå½¢çŠ¶ä¸º (140, 80) çš„å¼ é‡ï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªå¯¹æ•°æ¢…å°”é¢‘è°±å›¾ã€‚ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯åºåˆ—é•¿åº¦ï¼Œç”±äºè¯­éŸ³è§£ç å™¨å‰ç½®ç½‘ç»œæ€»æ˜¯å¯¹è¾“å…¥åºåˆ—è¿›è¡Œæ»¤æ³¢ï¼Œå› æ­¤åºåˆ—é•¿åº¦åœ¨ä¸åŒçš„è¿è¡Œä¸­å¯èƒ½ä¼šæœ‰æ‰€ä¸åŒã€‚è¿™å°±ç»™ç”Ÿæˆçš„è¯­éŸ³å¢åŠ äº†ä¸€äº›éšæœºå˜åŒ–ã€‚

ä¸è¿‡ï¼Œå¦‚æœæˆ‘ä»¬è¦ç”Ÿæˆè¯­éŸ³æ³¢å½¢ï¼Œå°±éœ€è¦æŒ‡å®šä¸€ä¸ªå£°ç å™¨ï¼Œç”¨äºä»é¢‘è°±å›¾åˆ°æ³¢å½¢çš„è½¬æ¢ã€‚ç†è®ºä¸Šï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä»»ä½•å¯ç”¨äº 80 åˆ†è´æ¢…å°”é¢‘è°±å›¾çš„å£°ç å™¨ã€‚æ–¹ä¾¿çš„æ˜¯ï¼ŒğŸ¤— `Transformers` æä¾›äº†åŸºäº HiFi-GAN çš„å£°ç å™¨ã€‚å…¶æƒé‡ç”± SpeechT5 çš„åŸä½œè€…å‹æƒ…æä¾›ã€‚

> [HiFi-GAN](https://arxiv.org/pdf/2010.05646v2.pdf)æ˜¯æœ€å…ˆè¿›çš„ç”Ÿæˆå¯¹æŠ—ç½‘ç»œ (GAN)ï¼Œä¸“ä¸ºé«˜ä¿çœŸè¯­éŸ³åˆæˆè€Œè®¾è®¡ã€‚å®ƒèƒ½ä»é¢‘è°±å›¾è¾“å…¥ç”Ÿæˆé«˜è´¨é‡ã€é€¼çœŸçš„éŸ³é¢‘æ³¢å½¢ã€‚ä»é«˜å±‚æ¥çœ‹ï¼ŒHiFi-GAN ç”±ä¸€ä¸ªç”Ÿæˆå™¨å’Œä¸¤ä¸ªåˆ¤åˆ«å™¨ç»„æˆã€‚ç”Ÿæˆå™¨æ˜¯ä¸€ä¸ªå…¨å·ç§¯ç¥ç»ç½‘ç»œï¼Œå®ƒå°† Mel é¢‘è°±å›¾ä½œä¸ºè¾“å…¥ï¼Œå¹¶å­¦ä¹ ç”ŸæˆåŸå§‹éŸ³é¢‘æ³¢å½¢ã€‚é‰´åˆ«å™¨çš„ä½œç”¨æ˜¯åŒºåˆ†çœŸå®éŸ³é¢‘å’Œç”ŸæˆéŸ³é¢‘ã€‚ä¸¤ä¸ªé‰´åˆ«å™¨å…³æ³¨éŸ³é¢‘çš„ä¸åŒæ–¹é¢ã€‚
>
> HiFi-GAN æ˜¯åœ¨é«˜è´¨é‡éŸ³é¢‘å½•éŸ³çš„å¤§å‹æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒçš„ã€‚å®ƒé‡‡ç”¨æ‰€è°“çš„*å¯¹æŠ—è®­ç»ƒ*ï¼Œå³ç”Ÿæˆå™¨ç½‘ç»œå’Œé‰´åˆ«å™¨ç½‘ç»œç›¸äº’ç«äº‰ã€‚èµ·åˆï¼Œç”Ÿæˆå™¨ä¼šç”Ÿæˆä½è´¨é‡çš„éŸ³é¢‘ï¼Œè€Œé‰´åˆ«å™¨å¯ä»¥å¾ˆå®¹æ˜“åœ°å°†å…¶ä¸çœŸå®éŸ³é¢‘åŒºåˆ†å¼€æ¥ã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œç”Ÿæˆå™¨ä¼šæ”¹è¿›å…¶è¾“å‡ºï¼Œä»¥éª—è¿‡é‰´åˆ«å™¨ã€‚åè¿‡æ¥ï¼Œé‰´åˆ«å™¨ä¹Ÿèƒ½æ›´å‡†ç¡®åœ°åŒºåˆ†çœŸå®éŸ³é¢‘å’Œç”ŸæˆéŸ³é¢‘ã€‚éšç€æ—¶é—´çš„æ¨ç§»ï¼Œè¿™ç§å¯¹æŠ—æ€§åé¦ˆå¾ªç¯æœ‰åŠ©äºä¸¤ä¸ªç½‘ç»œçš„æ”¹è¿›ã€‚æœ€ç»ˆï¼ŒHiFi-GAN å¯ä»¥å­¦ä¼šç”Ÿæˆä¸è®­ç»ƒæ•°æ®ç‰¹å¾éå¸¸ç›¸ä¼¼çš„é«˜ä¿çœŸéŸ³é¢‘ã€‚

åŠ è½½å£°ç å™¨ä¸åŠ è½½å…¶ä»– ğŸ¤— `Transformers` æ¨¡å‹ä¸€æ ·ç®€å•ã€‚

```python
from transformers import SpeechT5HifiGan 

vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")
```

ç°åœ¨åªéœ€åœ¨ç”Ÿæˆè¯­éŸ³æ—¶å°†å…¶ä½œä¸ºå‚æ•°ä¼ é€’ï¼Œè¾“å‡ºå°±ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºè¯­éŸ³æ³¢å½¢ã€‚

```python
speech = model.generate_speech(inputs["input_ids"], speaker_embeddings, vocoder=vocoder)
```

è®©æˆ‘ä»¬å¬å¬ç»“æœã€‚SpeechT5 ä½¿ç”¨çš„é‡‡æ ·ç‡å§‹ç»ˆæ˜¯ 16 kHzã€‚

```python
from IPython.display import Audio 

Audio(speech, rate=16000)
```

çœŸä¸é”™ï¼

è¯·éšæ„ä½¿ç”¨ SpeechT5 æ–‡æœ¬åˆ°è¯­éŸ³æ¼”ç¤ºï¼Œæ¢ç´¢å…¶ä»–è¯­éŸ³ï¼Œå°è¯•è¾“å…¥ã€‚è¯·æ³¨æ„ï¼Œè¿™ä¸ªé¢„è®­ç»ƒæ£€æŸ¥ç‚¹ä»…æ”¯æŒè‹±è¯­ã€‚

## **Bark** 

Bark æ˜¯Suno AI åœ¨ [suno-ai/bark](https://github.com/suno-ai/bark) ä¸­æå‡ºçš„åŸºäºTransformerçš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ã€‚

ä¸ SpeechT5 ä¸åŒçš„æ˜¯ï¼ŒBark ç›´æ¥ç”ŸæˆåŸå§‹è¯­éŸ³æ³¢å½¢ï¼Œæ— éœ€åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä½¿ç”¨å•ç‹¬çš„å£°ç å™¨--å®ƒå·²ç»é›†æˆäº†å£°ç å™¨ã€‚è¿™ç§æ•ˆç‡æ˜¯é€šè¿‡ä½¿ç”¨ [`Encodec`](https://huggingface.co/docs/transformers/main/en/model_doc/encodec) å®ç°çš„ï¼Œå®ƒæ—¢æ˜¯ç¼–è§£ç å™¨ï¼Œä¹Ÿæ˜¯å‹ç¼©å·¥å…·ã€‚

æœ‰äº† `Encodec`ï¼Œä½ å¯ä»¥å°†éŸ³é¢‘å‹ç¼©æˆè½»é‡çº§æ ¼å¼ï¼Œä»¥å‡å°‘å†…å­˜ä½¿ç”¨ï¼Œç„¶åå†è§£å‹ç¼©ä»¥æ¢å¤åŸå§‹éŸ³é¢‘ã€‚è¿™ä¸€å‹ç¼©è¿‡ç¨‹ç”± 8 ä¸ªç¼–ç æœ¬æä¾›ä¾¿åˆ©ï¼Œæ¯ä¸ªç¼–ç æœ¬éƒ½ç”±æ•´æ•°å‘é‡ç»„æˆã€‚å¯ä»¥å°†è¿™äº›ç¼–ç æœ¬è§†ä¸ºéŸ³é¢‘çš„æ•´æ•°å½¢å¼è¡¨ç¤ºæˆ–åµŒå…¥ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæ¯ä¸€ä¸ªè¿ç»­çš„ç¼–ç æœ¬éƒ½ä¼šæé«˜ä»ä¹‹å‰çš„ç¼–ç æœ¬é‡å»ºéŸ³é¢‘çš„è´¨é‡ã€‚ç”±äºç¼–ç æœ¬æ˜¯æ•´æ•°å‘é‡ï¼Œå› æ­¤å¯ä»¥é€šè¿‡ Transformer æ¨¡å‹æ¥å­¦ä¹ ï¼Œè€Œ Transformer æ¨¡å‹åœ¨è¿™é¡¹ä»»åŠ¡ä¸­éå¸¸é«˜æ•ˆã€‚è¿™æ­£æ˜¯ Bark ç»è¿‡ä¸“é—¨è®­ç»ƒåè¦åšçš„äº‹æƒ…ã€‚

å…·ä½“æ¥è¯´ï¼ŒBark ç”± 4 ä¸ªä¸»è¦æ¨¡å‹ç»„æˆï¼š 

- `BarkSemanticModel` æ¨¡å‹ï¼ˆä¹Ÿç§°ä¸º "æ–‡æœ¬ "æ¨¡å‹ï¼‰ï¼šè¿™æ˜¯ä¸€ä¸ªå› æœè‡ªå›å½’å˜æ¢å™¨æ¨¡å‹ï¼Œå®ƒå°†æ ‡è®°åŒ–æ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œå¹¶é¢„æµ‹èƒ½å¤Ÿæ•æ‰æ–‡æœ¬å«ä¹‰çš„è¯­ä¹‰æ–‡æœ¬æ ‡è®°ã€‚
- `BarkCoarseModel`ï¼ˆä¹Ÿç§°ä¸º "ç²—å£°å­¦ "æ¨¡å‹ï¼‰ï¼šè¿™æ˜¯ä¸€ä¸ªå› æœè‡ªå›å½’å˜æ¢æ¨¡å‹ï¼Œå°† `BarkSemanticModel` æ¨¡å‹çš„ç»“æœä½œä¸ºè¾“å…¥ã€‚å…¶ç›®çš„æ˜¯é¢„æµ‹ EnCodec æ‰€éœ€çš„å‰ä¸¤ä¸ªéŸ³é¢‘ç¼–ç æœ¬ã€‚
- `BarkFineModel`ï¼ˆ"ç²¾ç»†å£°å­¦ "æ¨¡å‹ï¼‰ï¼Œè¿™ä¸€æ¬¡æ˜¯ä¸€ä¸ªéå› æœè‡ªç¼–ç  Transformer ï¼Œå®ƒæ ¹æ®å‰ä¸€ä¸ªç¼–ç æœ¬åµŒå…¥çš„æ€»å’Œè¿­ä»£é¢„æµ‹æœ€åä¸€ä¸ªç¼–ç æœ¬ã€‚
- ä» `EncodecModel` ä¸­é¢„æµ‹å‡ºæ‰€æœ‰ç¼–ç æœ¬é€šé“åï¼ŒBark å°†å…¶ç”¨äºè§£ç è¾“å‡ºéŸ³é¢‘é˜µåˆ—ã€‚

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå‰ä¸‰ä¸ªæ¨¡å—ä¸­çš„æ¯ä¸€ä¸ªéƒ½å¯ä»¥æ”¯æŒæœ‰æ¡ä»¶çš„æ‰¬å£°å™¨åµŒå…¥ï¼Œä»¥æ ¹æ®ç‰¹å®šçš„é¢„å®šä¹‰è¯­éŸ³å¯¹è¾“å‡ºå£°éŸ³è¿›è¡Œè°ƒèŠ‚ã€‚

Bark æ˜¯ä¸€ç§é«˜åº¦å¯æ§çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥ä½¿ç”¨ä¸åŒçš„è®¾ç½®ï¼Œæ­£å¦‚æˆ‘ä»¬å°†è¦çœ‹åˆ°çš„é‚£æ ·ã€‚

é¦–å…ˆï¼ŒåŠ è½½æ¨¡å‹åŠå…¶å¤„ç†å™¨ã€‚

å¤„ç†å™¨çš„ä½œç”¨æ˜¯åŒé‡çš„ï¼š

1. å®ƒç”¨äºå¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œæ ‡è®°åŒ–ï¼Œå³æŠŠæ–‡æœ¬åˆ‡æˆæ¨¡å‹å¯ä»¥ç†è§£çš„å°å—ã€‚
2. å®ƒå­˜å‚¨è¯´è¯è€…åµŒå…¥ï¼Œå³å¯ä»¥ä½œä¸ºç”Ÿæˆæ¡ä»¶çš„è¯­éŸ³é¢„è®¾ã€‚

```python
from transformers import BarkModel, BarkProcessor 

model = BarkModel.from_pretrained("suno/bark-small") 
processor = BarkProcessor.from_pretrained("suno/bark-small")
```

Bark éå¸¸çµæ´»ï¼Œå¯ä»¥é€šè¿‡å¤„ç†å™¨åŠ è½½çš„[ `speaker embedding` åº“](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)ç”ŸæˆéŸ³é¢‘ã€‚

```python
# æ·»åŠ æ‰¬å£°å™¨åµŒå…¥
inputs = processor("This is a test!", voice_preset="v2/en_speaker_3")

speech_output = model.generate(**inputs).cpu().numpy()
```

å®ƒè¿˜èƒ½ç”Ÿæˆå³ç”¨å‹å¤šè¯­è¨€è¯­éŸ³ï¼Œå¦‚æ³•è¯­å’Œä¸­æ–‡ã€‚ä½ å¯ä»¥[åœ¨è¿™é‡Œ](https://huggingface.co/suno/bark)æ‰¾åˆ°æ”¯æŒçš„è¯­è¨€åˆ—è¡¨ã€‚ä¸ä¸‹æ–‡è®¨è®ºçš„MMSä¸åŒï¼Œå®ƒæ— éœ€æŒ‡å®šä½¿ç”¨çš„è¯­è¨€ï¼Œåªéœ€å°†è¾“å…¥æ–‡æœ¬è°ƒæ•´ä¸ºç›¸åº”çš„è¯­è¨€å³å¯ã€‚

```python
# åœ¨æ³•è¯­ä¸­è¯•ç”¨ï¼Œè®©æˆ‘ä»¬ä¹Ÿæ·»åŠ ä¸€ä¸ªæ³•è¯­å‘è¨€äººåµŒå…¥
inputs = processor("C'est un test!", voice_preset="v2/fr_speaker_1") 

speech_output = model.generate(**inputs).cpu().numpy()
```

è¯¥æ¨¡å‹è¿˜èƒ½ç”Ÿæˆ***\*éè¯­è¨€äº¤æµ\****ï¼Œå¦‚å¤§ç¬‘ã€å¹æ¯å’Œå“­æ³£ã€‚æ‚¨åªéœ€ç”¨ç›¸åº”çš„æç¤ºè¯­ä¿®æ”¹è¾“å…¥æ–‡æœ¬ï¼Œå¦‚`[clear thorat]`ã€`[laughter]` æˆ–`....`

```python
inputs = processor(
	"[clears throat] This is a test ... and I just took a long pause.", 		    voice_preset="v2/fr_speaker_1", ) 
	
speech_output = model.generate(**inputs).cpu().numpy()
```

Bark ç”šè‡³å¯ä»¥ç”ŸæˆéŸ³ä¹ã€‚ä½ å¯ä»¥åœ¨ä½ çš„è¯è¯­å‘¨å›´æ·»åŠ éŸ³ç¬¦ã€‚

```python
inputs = processor(
	"â™ª In the mighty jungle, I'm trying to generate barks.", 
) 

speech_output = model.generate(**inputs).cpu().numpy()
```

é™¤äº†æ‰€æœ‰è¿™äº›åŠŸèƒ½å¤–ï¼ŒBark è¿˜æ”¯æŒæ‰¹å¤„ç†ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥åŒæ—¶å¤„ç†å¤šä¸ªæ–‡æœ¬æ¡ç›®ï¼Œä½†ä»£ä»·æ˜¯éœ€è¦è¿›è¡Œæ›´å¯†é›†çš„è®¡ç®—ã€‚åœ¨æŸäº›ç¡¬ä»¶ï¼ˆå¦‚ GPUï¼‰ä¸Šï¼Œæ‰¹å¤„ç†å¯ä»¥åŠ å¿«æ•´ä½“ç”Ÿæˆé€Ÿåº¦ï¼Œè¿™æ„å‘³ç€ä¸€æ¬¡ç”Ÿæˆæ‰€æœ‰æ ·æœ¬æ¯”é€ä¸ªç”Ÿæˆæ ·æœ¬æ›´å¿«ã€‚

è®©æˆ‘ä»¬è¯•ç€ç”Ÿæˆå‡ ä¸ªç¤ºä¾‹ï¼š

```python
input_list = [ 
	"[clears throat] Hello uh ...ï¼Œmy dog is cute [laughter]", 
	"Let's try generating speech, with Bark, a text-to-speech model", 
	"â™ª In the jungle, the mighty jungle, the lion barks tonight â™ª", 
]  
# è¿˜æ·»åŠ äº†æ‰¬å£°å™¨åµŒå…¥
inputs = processor(input_list, voice_preset="v2/en_speaker_3") 

speech_output = model.generate(**inputs).cpu().numpy()
```

è®©æˆ‘ä»¬é€ä¸€å¬å¬è¾“å‡ºç»“æœã€‚

ç¬¬ä¸€ä¸ª

```python
from IPython.display import Audio 

sampling_rate = model.generation_config.sample_rate 
Audio(speech_output[0], rate=sampling_rate)
```

ç¬¬äºŒä¸ª

```python
Audio(speech_output[1], rate=sampling_rate)
```

ç¬¬ä¸‰ä¸ª

```python
Audio(speech_output[2], rate=sampling_rate)
```

>  Bark å’Œå…¶ä»– ğŸ¤— Transformer æ¨¡å‹ä¸€æ ·ï¼Œåªéœ€å‡ è¡Œä»£ç å°±èƒ½å¯¹é€Ÿåº¦å’Œå†…å­˜å½±å“è¿›è¡Œä¼˜åŒ–ã€‚è¦äº†è§£å¦‚ä½•ä¼˜åŒ–ï¼Œè¯·å•å‡»[æ­¤colabæ¼”ç¤ºç¬”è®°æœ¬](https://colab.research.google.com/github/ylacombe/notebooks/blob/main/Benchmark_Bark_HuggingFace.ipynb)ã€‚

## **å¤§è§„æ¨¡å¤šè¯­è¨€è¯­éŸ³ (MMS)** 

å¦‚æœæ‚¨æ­£åœ¨å¯»æ‰¾è‹±è¯­ä»¥å¤–è¯­è¨€çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œè¯¥æ€ä¹ˆåŠï¼Ÿå¤§è§„æ¨¡å¤šè¯­è¨€è¯­éŸ³ (MMS) æ˜¯å¦ä¸€ç§æ¶µç›–ä¸€ç³»åˆ—è¯­éŸ³ä»»åŠ¡çš„æ¨¡å‹ï¼Œä½†å®ƒæ”¯æŒå¤§é‡è¯­è¨€ã€‚ä¾‹å¦‚ï¼Œå®ƒå¯ä»¥åˆæˆ 1100 å¤šç§è¯­è¨€çš„è¯­éŸ³ã€‚

ç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³çš„ MMS åŸºäº[VITS](https://arxiv.org/pdf/2106.06103.pdf)ï¼Œå®ƒæ˜¯æœ€å…ˆè¿›çš„ TTS æ–¹æ³•ä¹‹ä¸€ã€‚

VITS æ˜¯ä¸€ç§è¯­éŸ³ç”Ÿæˆç½‘ç»œï¼Œå¯å°†æ–‡æœ¬è½¬æ¢ä¸ºåŸå§‹è¯­éŸ³æ³¢å½¢ã€‚å®ƒçš„å·¥ä½œåŸç†ç±»ä¼¼äºæ¡ä»¶å¼å˜æ¢è‡ªç¼–ç æœºï¼Œä»è¾“å…¥æ–‡æœ¬ä¸­ä¼°è®¡éŸ³é¢‘ç‰¹å¾ã€‚é¦–å…ˆï¼Œç”Ÿæˆä»¥é¢‘è°±å›¾è¡¨ç¤ºçš„å£°éŸ³ç‰¹å¾ã€‚ç„¶åï¼Œä½¿ç”¨ä» HiFi-GAN æ”¹ç¼–è€Œæ¥çš„è½¬ç½®å·ç§¯å±‚å¯¹æ³¢å½¢è¿›è¡Œè§£ç ã€‚åœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨æµæ¨¡å—å’Œ HiFiGAN è§£ç å™¨å¯¹æ–‡æœ¬ç¼–ç è¿›è¡Œä¸Šé‡‡æ ·å¹¶è½¬æ¢æˆæ³¢å½¢ã€‚ä¸ Bark ä¸€æ ·ï¼Œä¸éœ€è¦å£°ç å™¨ï¼Œå› ä¸ºæ³¢å½¢æ˜¯ç›´æ¥ç”Ÿæˆçš„ã€‚

>  MMS æ¨¡å‹æœ€è¿‘æ‰æ·»åŠ åˆ° ğŸ¤— Transformers ä¸­ï¼Œå› æ­¤æ‚¨å¿…é¡»ä»æºä»£ç å®‰è£…è¯¥åº“ï¼š
>
> ```
> pip install git+https://github.com/huggingface/transformers.git
> ```

è®©æˆ‘ä»¬è¯•ä¸€è¯• MMSï¼Œçœ‹çœ‹å¦‚ä½•ç”¨è‹±è¯­ä»¥å¤–çš„è¯­è¨€ï¼ˆå¦‚å¾·è¯­ï¼‰åˆæˆè¯­éŸ³ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬è¦ä¸ºæ­£ç¡®çš„è¯­è¨€åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹å’Œæ ‡è®°å™¨ï¼š

```python
from transformers import VitsModel, VitsTokenizer 

model = VitsModel.from_pretrained("facebook/mms-tts-deu") 
tokenizer = VitsTokenizer.from_pretrained("facebook/mms-tts-deu")
```

æ‚¨å¯èƒ½ä¼šæ³¨æ„åˆ°ï¼Œè¦åŠ è½½ MMS æ¨¡å‹ï¼Œéœ€è¦ä½¿ç”¨ `VitsModel` å’Œ `VitsTokenizer` ã€‚è¿™æ˜¯å› ä¸ºæ–‡æœ¬åˆ°è¯­éŸ³çš„ MMS æ˜¯åŸºäºå‰é¢æåˆ°çš„ VITS æ¨¡å‹ã€‚

è®©æˆ‘ä»¬é€‰å–ä¸€ä¸ªå¾·è¯­æ–‡æœ¬ç¤ºä¾‹ï¼Œæ¯”å¦‚ä¸€é¦–å„¿æ­Œçš„å‰ä¸¤è¡Œï¼š

```python
text_example = (
	"Ich bin Schnappi das kleine Krokodil, komm aus Ã„gypten das liegt direkt am Nil."
)
```

è¦ç”Ÿæˆæ³¢å½¢è¾“å‡ºï¼Œè¯·ä½¿ç”¨ tokenizer å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™æ¨¡å‹ï¼š

```python
import torch 

inputs = tokenizer(text_example, return_tensors="pt") 
input_ids = inputs["input_ids"] 

with torch.no_grad(): 
	outputs = model(input_ids) 
	
speech = outputs["waveform"]
```

è®©æˆ‘ä»¬æ¥å¬ä¸€å¬ï¼š

```python
from IPython.display import Audio 

Audio(speech, rate=16000)
```

å¤ªæ£’äº†ï¼å¦‚æœæ‚¨æƒ³å°è¯•ä½¿ç”¨å…¶ä»–è¯­è¨€MMSï¼Œè¯·åœ¨ [ğŸ¤— Hub]((https://huggingface.co/models?filter=vits)) ä¸ŠæŸ¥æ‰¾å…¶ä»–åˆé€‚çš„ `vits` æ£€æŸ¥ç‚¹ã€‚

ç°åœ¨ï¼Œè®©æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•è‡ªè¡Œå¾®è°ƒ TTS æ¨¡å‹ï¼
